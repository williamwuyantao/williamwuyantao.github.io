---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
------

* Ph.D. program in Mathematics, 2021 - Now
  * Research Topics: Nonparametric Statistical Learning, Theoretical Machine Learning, Supervised Learning Theory, Parabolic Partial Differential Equations.
  * Coursework: Riemannian Geometry, Algebraic Topology, Harmonic Analysis, Partial Differential Equations, Stochastic Differential Equation, High-Dimensional Probability, Probabilistic Machine Learning
and Diffusion Generative Models, Stochastic Controls and Reinforcement Learning, coding Large Language Models.
* B.S. in Mathematics & B.A. in Physics, Syracuse University, 2018 - 2021
  * *Summa Cum Laude* (Cumulative GPA: 3.992/4.000)
  * Distinction in Mathematics
  * Syracuse University Scholar
  * Member of Phi Beta Kappa
  * Math Department Awards: Euclid Prize in 2020 & Archimedes Prize in 2021 
  * Physics Department Award: Neil F. Beardsley Prize in 2021

Academic Awards
------

* Chinese Mathematical Olympiad: First prize in provincial level in 2017
* Chinese Physics Olympiad: First prize in provincial level in 2017
* William Lowell Putnam Mathematical Competition: ranked in top 15% nationwide in 2018&2019

Research Topics:
------

* Nonparametric Statistical Learning
We consider nonlinear functional compositional structures that generalize the linear single-index or multi-
index model, and develop new algorithms to achieve the goal of obtaining the minimax nonparametric
rate corresponding without suffering from the curse of dimensionality. These novel algorithms cover a
wide range of tools from statistical learning, including conditional regression, local kernel regression, gra-
dient estimates, nonlinear feature learning, and high dimensional classification. The proposed minimax
nonparametric rate is both proved in theoretically and verified in numerical simulations.
* Theoretical Machine Learning
Study theoretical analysis of neural networks, including random feature model, Weisserstein Gradient
Flow, neural tangent kernels, and maximal update parameterization in hyper-parameter transfer. In
particular, our research cover the topics of error landscape in the problem of learning single-index and
multi-index model via neural networks. Moreover, our research cover topics of use interacting particle
systems and its mean-field limit McKean-Vlasov Equation to study mathematical foundation of MLP
and transformer.
* Regularity vs Singularity in Parabolic PDEs
We consider the problem of regularity of solutions to different types of geometric variational problems of
partially constrained free boundary, motivated by classical results on regularity vs singularity formation in heat flows of harmonic map. We also study active scalar equations where the fractional Laplacian gives
many open problems, for example, Regularity vs Singularity in Surface Quasi-Geostrophic equation.


Teaching Experience
------

* Syracuse University: 
  * Math help room: tutor students on elementary Calculus. 
  * Teaching Assistant: MAT 412: Introduction to Real Analysis I, MAT 517: Partial Differential Equations and Fourier Series, and MAT 534: Introduction to Abstract Algebra.
* Johns Hopkins University:
  * Math help room: tutor students on undergraduate math courses.
  * Teaching Assistant: Math 107: Calculus II, Math 201: Linear Algebra , Math 202: Calculus III, Math 311: Methods in Complex Analysis.

Technical Skills
------

* Programming Languages: Matlab, Python, Mathematica 
* Software & Tools Microsoft Office, LATEX
